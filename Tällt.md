Dear Sir / Madam,

I am a recent graduate looking to start my early career in a startup / small company with a focus in software development and data engineering. I am fascinated by the relationship between technology and data, especially in how it can create business value. 

### Data Engineering

Movie Credits Project:

> Movie credits, my focus on this project was data cleaning, and extraction of the relevant information to the task. In summary, it required data filtering, data manipulation and data formatting to create an adjacency matrix for enabling analysis with network theory . 

**Concepts used: Data engineering with Python, Object-oriented Programming**.

This project was heavily a programming problem so here is a collection of the scripts that I wrote for this project:

[https://github.com/horken7/movie-credits/blob/master/moviecredits/utils/generate_all.py](https://github.com/horken7/movie-credits/blob/master/moviecredits/utils/generate_all.py)

[https://github.com/horken7/movie-credits/blob/master/moviecredits/connections.py](https://github.com/horken7/movie-credits/blob/master/moviecredits/connections.py)

[https://github.com/horken7/movie-credits/blob/master/moviecredits/lookup.py](https://github.com/horken7/movie-credits/blob/master/moviecredits/lookup.py)

[https://github.com/horken7/movie-credits/tree/master/moviecredits/utils](
https://github.com/horken7/movie-credits/tree/master/moviecredits/utils)


### Machine Learning Knowledge

Final year project:
* Implemented and adapted a Twitter text tokenizer for detecting tokens that are unique to Twitter messages.
* Filtered out tokens that appear to often using TF-IDF algorithm and building a Feature set.
* Applied the feature set to convert Twitter messages into a vector.
* Applied Naive Bayes, Decision Tree and Random Forest algorithm to the processed labelled data to carry out a comparison of the models.
* Deployed the best performing ML algorithm on a Flask webserver so it could be used on a web application that pulls messages from Twitter user timelines.

**Concents used: NLP, Feature Engineering, Machine Learning, Flask web framework**.

Statistical Pattern Recognition Course:

Learned about the mathematical background behind ML algorithms which includes: Perceptron, Support Vector Machines, Least Squares, Nearest Neighbour, K-means, Principal Component Analysis.


### Data Science

Circadian Rhythm Project:

> Circadian Rhythm, my focus on this project was mainly on the sleep detection. We were given accelerometer data obtained from the SPHERE project and were assigned to detect sleep. This was considered an unsupervised classification. By the end of the project we managed to implement a centroid based clustering algorithm known as k-means. Evaluation for the performance of the k-means algorithm was difficult since the data given was unlabelled. This project was relevant to health, home
automation and many other companies that want to understand human sleep patterns. 

**Concepts used: Data Engineering, statistical analysis, k-nearest neighbour**.
**Technologies used: Python, pandas, scikit-learn, numpy, matplotlib.**

The code can be seen below:

[https://github.com/horken7/circadian-rhytm/blob/master/analyseSleep.ipynb](https://github.com/horken7/circadian-rhytm/blob/master/analyseSleep.ipynb)


### Team Player
> "Andrew quickly became a valuable member of our team, settling in easily and making improvements to our development processes. He is a self-motivated individual that took responsibility of tasks and kept other team members updated with his progress. He was never afraid to ask for help, but always attempted (and mostly succeeded) to research and implement a solution before asking others. Andrew put forward a number of excellent ideas during his time with us about product development and our processes, all of which have now been implemented in the business and have shown to have a positive impact on our output."

*Reference from Miminal*

### Commercial Experience

**Miminal's blog website**:

> Gained experience with the entire software life cycle excluding deployment; from tech review to creation of the website.
The project exposed me to a lot of different technologies and gained front end experience.

**Concepts used: Mobile responsive design, tech stack review, front-end development.**
**Technolgies used: Hexo.js, SASS, Pug.js, Bootstrap4** .

Full Article can be read here: [https://kankyu.github.io/web%20development/2018/09/01/miminalwebsite.html](https://kankyu.github.io/web%20development/2018/09/01/miminalwebsite.html)

---
**Miminal's client (KADlytics)**:
> Developed visualisations from AI analytics for communicating to project managers. I also worked on backend development; Creating schemas, building a pipeline for inserting data into the MongoDB web app database, and passing the inserted data into visualisations.

**Concepts used: AI analytics Visualisations, component-based paradigm (with React), schemas, Database insertion and querying**. 

**Technologies used: React & Ant Design, and MongoDB (a noSQL database)**.

### Motivation to join Tällt

Recently finished an internship as a software developer at a startup called Miminal, I am now looking to transition into a growing startup that will give me the opportunity to learn a varied set of technical skills.

I believe Tällt will give me this opportunity to learn a versatile skillset and be able to grow with the company.

Thank you for reading this covering letter, and I look forward to hearing from you.

Yours faithfully,
Andrew